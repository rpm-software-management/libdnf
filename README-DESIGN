A libdnf::Base instance is a center of all business logic.
It's purpose is to integrate remaining libdnf classes
and it's not implementing any complex business logic by itself.

Every content type (rpm, comps, etc.) implements it's own
libdnf::<content_type>::Base class that integrates all classes
managing the content type.

These clases are usually following:
- Sack - high-level abstraction on package data (libsolv pool, comps xml, ...)
- Query - query interface on Sack that returns PackageSet
- Package - object interface to packages from Sack; doesn't carry any data, just interfaces Sack
- PackageSet - represents a set of packages + operations on it
- Goal - dependency resolver
- Selector - 

Solution = string -> nevra and/or query; formerly - getBestQuery/Nevra/Solution

dnf install '*dnf'
getBestSelectors('*dnf', sack)
    -> getBestSolution('*dnf', sack)
        -> parse '*dnf', tries NEVRA_FORMs, if there's a non-empty query for a form, return the query
    -> transform query to {name: [pkgs]} dict
    -> for each such group by name, create a selector
    -> list of selectors == candidates for install jobs

for each selector:
    goal.install(sel)


GPG: if a key is distributed in a signed rpm, can we trust it automatically? (chain of trust)


tsflags=test / --assumeno : don't log, don't update history; only import GPG keys


excludes/includes only for available packages
- well documented change in dnf5 (would break dnf4)
- currently affects versionlock?


fix debug/verbose modes
 - debug to report what dnf/libdnf is doing
 - verbose to add more details to user output
 - remove tracebacks from logs?
   - make sure that debug info is still available


--help
 - group commands, options
 - make sure the general help is way shorter than in dnf4


lukash:
  - we really really should separate reposync from the actual commands
    - aptitude does it that way, all the other package managers do it that way
    - it is annoying
    - it allows to only sync to the system cache location under root, non-privileged dnf calls can use it as read-only and there should be no user cache under normal circumstances
      - it basically halves the bandwidth that DNF uses, which is A LOT
      - the cache isn't stored twice (or more in multi-user environment!) on the harddisk
      - we can have a special solution for special setups where the user wants to work on non-system repos
    - it is also very annoying

  - list of user-installed packages and installed groups shouldn't be stored history.sqlite


FUTURE:
lazy evaluation (for modularity)

object:
    input: '*dnf'
    demands: (make read-only copy, global config changes must note change it)
    "resolve() == getBestSelectors()"
>   name: pset/query

goal install (sltr) == for name, q in sltr: goal.install(oneof(q))


Configurable vendor stickiness (allow_vendor_change=true); rhbz#1788371


forward/backward actions -> in/out actions

Must compile with both gcc and clang.

Tests:
* use MALLOC_PERTURB_
* use sanitizers


Coding style checks
-------------------
* clang-format-diff
* clang-tidy-diff
* rpmlint
* cmake-lint - https://github.com/richq/cmake-lint
* executed on every pull request
* executed before every merge to master
* possible to run locally before submitting a PR


Soname versioning
-----------------
https://github.com/rpm-software-management/microdnf/pull/64#issuecomment-568213701
Conan-Kudo: We probably should be doing soname bumps instead, or making it so that there are versioned symbol exports similar to to libsolv and glibc so that when you use new functionality, that gets represented in an rpm dependency automatically...


Workflow:
* make sure that the functions cannot be called in the wrong order
* shortcuts for certain types of workflows
  * initialize the library the same way DNF is initialized (logging, configuration, etc.)
  * initialize the library for making queries to ad-hoc repos


Queries:
base.rpm.query <-- existing Query() instance (libdnf::rpm::Query)
base.comps.group_query (libdnf::generic::Query<libdnf::comps::Group>)
    .filter(id="base") -> works on libdnf::comps::Group.id
base.comps.environment_query
    .filter(id="base") -> works on libdnf::comps::Environment.id
^^^ just an overall idea; another options would be
    additional 'Base' objects per content type
    or package specific Sacks (they are "package" containers)


Pointer ownership - clearly document who is responsible for deleting


Choose pointer types for related objects (Base, Sack, Package, etc.) and handle their life cycle
------------------------------------------------------------------------------------------------

Scenario 1: reset sack
b = Base()
b.fill_sack()
pkg = b.sack.query(...)
b.reset()
print(pkg.name)
expected result: throws an exception that underlying data (sack) is no longer available

Scenario 2: free sack / base
b = Base()
b.fill_sack()
pkg = b.sack.query(...)
delete base
print(pkg.name)
expected result: throws an exception that underlying data (sack) is no longer available

Scenario 3: using a package with a different sack
b1 = Base()
b1.fill_sack()
pkg = b1.sack.query(...)
b2 = Base()
b2.fill_sack()
b2.sack.query(pkg=pkg)
expected result: throws an exception that package is used with a different sack than it comes from


Configs:
conf.d directories, systemd-like overrides
libeconf or use a custom code for now?


Copyright:
* cleanup: all @redhat.com personal copyright claims -> (c) Red Hat
* CLA?
* PR review - test if license text is present; it must have accurate date?


Types:
* use C++ types unless there's proven impact on performance
* if performance is an issue, use C types in private API


Package support:
* basic support for loading DEBs - incl. classes inherited from libdnf::rpm classes; shared Sack
* API for creating packages on fly (for Pulp)


Config / demands:
* Demands are usually related to configuring a goal


Advisories:
* need to be reworked
* AdvisorySet + queries
  * Advisory
    * RPMs
    * Modules
    * references

Building:
  lukash:
    * decide on meson vs CMake? (meson doesn't natively support Swift, although it wouldn't be terribly hard to add that)


Debugging:
* run command with debugsolver
* create archive with
  * debugsolver data (modular, non-modular, others)
  * logs
  * configs
  * list of plugins
* Suggest how to upload the data to bugzilla or elsewhere


Dependencies
------------
* Hide all libsolv internals, libsolv header files should not be necessary to use libdnf


C++ specifics
-------------
* Avoid lambda (lukash: why, there's nothing inherently wrong with lambdas)
* use // and /// comments; make block comments available for debugging (commenting out parts of code)
* Write documentation strings to the header files. They are part of public API.
* Avoid writing inline method directly to the class headers. They make the headers harder to read.


Concurrency
-----------
Base should implement a workflow and locking for readers/writers.


Logging
-------
  lukash:
    * we need to decide if:
      a) libdnf will log by itself and potentially provide logging functions for the API user to use for logging (we'll probably need that if we want to log to a single file?)
      b) libdnf should be provided with a log callback and log through that
    * it would be best to use an established facility for logging, most advanced of which is journald, alternatively the system logger
    * libdnf shouldn't use the logger to print user-facing output to stderr - those messages need to go through the API


Exceptions
----------
* Reduce number of exception nested in classes
  Group all exceptions in namespace in exceptions.hpp instead
  It's better for portability into other languages

  lukash:
    * The exception system needs to defferentiate between expected (e.g. file not found) and unexpected (programmer errors, crashes) errors
    * lets not use the likes of std::runtime_error at all just to keep a clean design
    * we should either:
      * set up a way to log exception tracebacks (there are tools for that, albeit they have some drawbacks, it's the best we can do)
      * do not catch the unexpected exceptions, which results in terminate() and we can get a traceback with gdb

  jrohel:
    * consider a single exception class with details inside
    * it could also work for dbus out of the box


THE PLAN
--------
* branch master to dnf-4-maint
* branch master to dnf-5-devel
* freeze master
  * if DNF 5 development succeeds, merge dnf-5-devel into master
  * if DNF 5 development fails, merge dnf-4-maint into master
* the big bang
  * all APIs are considered unstable in the dnf-5-devel branch
  * C context API goes away
  * hawkey goes away
  * existing microdnf codebase goes away (glib will be replaced with C++ -> brand new code)
  * run clang-format on the whole project
  * run clang-tidy on the whole project
  * create a config file with revisions to be ignored when running git blame to skip the format changes
* rewrite
  * replace existing code with the new classes (new C++ API)
  * any time an existing public class, method or function gets removed, new code MUST contain a reference to it (@replaces keyword in the doc text)
  * every change MUST come with a unit test
* stabilization
  * create a C++ program that is able to install a package
    * this will become a base for new microdnf
    * OUT OF SCOPE: handling command-line arguments
    * OUT OF SCOPE: printing any outputs
  * continue rewriting the code in order to make DNF work again (ci-dnf-stack passing)
    * 2w sprints, make plans according to the critical path towards getting most important functionality back
* DBus API
  * Make sure that libdnf-cli library/API works for dnf, microdnf and also DBus command-line client
    (don't rely on objects, pointers, ... pass data structures to the libdnf-cli API)
  * Work on DBus API in parallel with the rewrite in order to verify that the APIs were designed correctly
